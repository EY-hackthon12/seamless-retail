# Optimized GPU Dockerfile for "Extreme Speed" LLM Hosting
FROM pytorch/pytorch:2.1.2-cuda12.1-cudnn8-runtime

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    git \
    ninja-build \
    && rm -rf /var/lib/apt/lists/*

# Install specific Python dependencies for High Performance
# vLLM provides the PagedAttention and optimized kernels
RUN pip install --no-cache-dir vllm==0.3.0

# Install other app dependencies
COPY requirements.txt .
# Filter out conflicting torch/transformers versions from requirements.txt if necessary
# For now, we assume requirements.txt is compatible or we force reinstall
RUN pip install --no-cache-dir -r requirements.txt

# Copy backend code
COPY . .

# Environment variables for Optimization
ENV PYTHONUNBUFFERED=1
ENV VLLM_WORKER_MULTIPROC_METHOD=spawn

# Expose port
EXPOSE 8000

# Run the optimized host
CMD ["python", "scripts/hosting/serve_optimized.py", "--port", "8000"]
