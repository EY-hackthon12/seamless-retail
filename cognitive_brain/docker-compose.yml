version: '3.8'

services:
  brain-api:
    build:
      context: .
      dockerfile: docker/Dockerfile.brain
    ports:
      - "8000:8000"
    environment:
      - REDIS_URL=redis://redis:6379
      - CHROMA_URL=http://chromadb:8000
      - VLLM_URL=http://vllm:8002
      - LLAMA_URL=http://llama:8003
    depends_on:
      - redis
      - chromadb
    volumes:
      - ./models:/app/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 30s
      timeout: 10s
      retries: 3

  vllm:
    image: vllm/vllm-openai:latest
    ports:
      - "8002:8002"
    environment:
      - MODEL_PATH=${MODEL_PATH:-mistralai/Mistral-7B-Instruct-v0.3}
      - QUANTIZATION=${QUANTIZATION:-awq}
      - GPU_MEMORY_UTILIZATION=0.90
      - MAX_MODEL_LEN=8192
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
      - ./models:/app/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    command: >
      --model ${MODEL_PATH:-mistralai/Mistral-7B-Instruct-v0.3} --port 8002 --gpu-memory-utilization 0.90

  llama:
    build:
      context: .
      dockerfile: docker/Dockerfile.llama
    ports:
      - "8003:8003"
    environment:
      - GGUF_MODEL_PATH=/app/models/mistral-7b.Q4_K_M.gguf
      - N_GPU_LAYERS=-1
      - N_CTX=4096
    volumes:
      - ./models:/app/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]

  triton:
    image: nvcr.io/nvidia/tritonserver:24.08-py3
    ports:
      - "8001:8001"
      - "8004:8000"
    volumes:
      - ./cognitive_brain/inference/triton/model_repository:/models
    command: tritonserver --model-repository=/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes

  chromadb:
    image: chromadb/chroma:latest
    ports:
      - "8005:8000"
    volumes:
      - chroma_data:/chroma/chroma
    environment:
      - ANONYMIZED_TELEMETRY=False

volumes:
  redis_data:
  chroma_data:


networks:
  default:
    name: cognitive_brain_network
